{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copied from https://colab.research.google.com/drive/1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX#scrollTo=Z474sSC6oe7A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DEfSbAA4QHas",
    "outputId": "a6536544-6bd1-462a-d946-ec6bdb8a1a2d"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # Get the GPU device name.\n",
    "# device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# # The device name should look like the following:\n",
    "# if device_name == '/device:GPU:0':\n",
    "#     print('Found GPU at: {}'.format(device_name))\n",
    "# else:\n",
    "#     raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "oYsV4H8fCpZ-",
    "outputId": "47d8fbc6-39b6-4067-a37b-c792342c54b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce RTX 2070\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# tasks = ['cola', 'MRPC']\n",
    "TASK = 'MRPC'\n",
    "import pdb\n",
    "\n",
    "def get_device():\n",
    "  # If there's a GPU available...\n",
    "  if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "  # If not...\n",
    "  else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "  return device\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "id": "0NmMdkZO8R6q",
    "outputId": "81878b39-ed58-4dce-cf0a-24ef4a470dfd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\leedt\\anaconda3\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc1 in c:\\users\\leedt\\anaconda3\\lib\\site-packages (from transformers) (0.8.1rc1)\n",
      "Requirement already satisfied: requests in c:\\users\\leedt\\anaconda3\\lib\\site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\leedt\\anaconda3\\lib\\site-packages (from transformers) (4.42.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\leedt\\anaconda3\\lib\\site-packages (from transformers) (2020.7.14)\n",
      "Requirement already satisfied: packaging in c:\\users\\leedt\\anaconda3\\lib\\site-packages (from transformers) (20.1)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in c:\\users\\leedt\\anaconda3\\lib\\site-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: filelock in c:\\users\\leedt\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy in c:\\users\\leedt\\anaconda3\\lib\\site-packages (from transformers) (1.18.1)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\leedt\\anaconda3\\lib\\site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\leedt\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\leedt\\anaconda3\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\leedt\\anaconda3\\lib\\site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\leedt\\anaconda3\\lib\\site-packages (from requests->transformers) (1.25.10)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\leedt\\anaconda3\\lib\\site-packages (from packaging->transformers) (2.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\leedt\\anaconda3\\lib\\site-packages (from packaging->transformers) (1.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\leedt\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\leedt\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (0.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5m6AnuFv0QXQ",
    "outputId": "dad7440c-0ec0-4d80-b80d-a6f96efa7787"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\leedt\\anaconda3\\lib\\site-packages (3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pMtmPMkBzrvs",
    "outputId": "8923f4fa-e40c-412d-a644-f65793c3cd9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset...\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "import os\n",
    "\n",
    "print('Downloading dataset...')\n",
    "\n",
    "def download_data(task):\n",
    "  task_to_data = {\n",
    "    'cola': ('https://nyu-mll.github.io/CoLA/cola_public_1.1.zip', './cola_public_1.1.zip', './cola_public/')\n",
    "  }\n",
    "  if task != 'cola':\n",
    "        return\n",
    "  url, download_file, unzip_file = task_to_data[task]\n",
    "  \n",
    "  # Download the file (if we haven't already)\n",
    "  if not os.path.exists(download_file):\n",
    "      wget.download(url, download_file)\n",
    "      \n",
    "  # Unzip the dataset (if we haven't already)\n",
    "  if not os.path.exists(unzip_file):\n",
    "      !unzip $unzip_file\n",
    "\n",
    "download_data(\"cola\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_examples(lines, set_type):\n",
    "    \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "    examples = []\n",
    "    for (i, line) in enumerate(lines):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        guid = \"%s-%s\" % (set_type, i)\n",
    "        text_a = convert_to_unicode(line[3])\n",
    "        text_b = convert_to_unicode(line[4])\n",
    "        if set_type == \"test\":\n",
    "            label = \"0\"\n",
    "        else:\n",
    "            label = convert_to_unicode(line[0])\n",
    "        examples.append(\n",
    "          {'guid':guid, 'text_a':text_a, 'text_b':text_b, 'label':label})\n",
    "    return pd.DataFrame(examples)\n",
    "\n",
    "def read_tsv(input_file, quotechar=None):\n",
    "    \"\"\"Reads a tab separated value file.\"\"\"\n",
    "    with open(input_file, \"r\", encoding=\"utf8\") as f:\n",
    "        reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
    "        lines = []\n",
    "        for line in reader:\n",
    "            lines.append(line)\n",
    "        return lines\n",
    "def convert_to_unicode(text):\n",
    "    if isinstance(text, str):\n",
    "        return text\n",
    "    elif isinstance(text, bytes):\n",
    "        return text.decode(\"utf-8\", \"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "_UkeC7SG2krJ",
    "outputId": "47ae0de6-4c95-4b82-ad0f-e3fb27b8ef76",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "def load_data(sample_data = False):\n",
    "    if TASK == 'cola':\n",
    "        # Load the dataset into a pandas dataframe.\n",
    "        df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, \n",
    "                                         names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "    if TASK == 'MRPC':\n",
    "        return pd.concat((\n",
    "            [create_examples(read_tsv('glue_data/MRPC/' + name + '.tsv'), name) \n",
    "             for name in ['train', 'dev', 'test']]), axis=0)\n",
    "\n",
    "        # Report the number of sentences.\n",
    "    print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
    "    \n",
    "    if sample_data:\n",
    "        df = df.head(sample_data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Z474sSC6oe7A",
    "outputId": "7e93e7c9-9edf-473b-dbe9-eb78cdab6996"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leedt\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\leedt\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\leedt\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\leedt\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\leedt\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\leedt\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cKsH2sU0OCQA",
    "outputId": "0a95553f-5911-419f-b12f-f72b8f56a235"
   },
   "outputs": [],
   "source": [
    "# # max_len = 0\n",
    "\n",
    "# # # For every sentence...\n",
    "# # for sent in sentences:\n",
    "\n",
    "# #     # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "# #     input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "\n",
    "# #     # Update the maximum sentence length.\n",
    "# #     max_len = max(max_len, len(input_ids))\n",
    "\n",
    "# # print('Max sentence length: ', max_len)\n",
    "\n",
    "# max_len = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "2bBdb3pt8LuQ",
    "outputId": "b34143b4-dac4-4240-ee92-f3694fd566f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  ['Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .', 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .']\n",
      "Token IDs: tensor([  101,  2572,  3217,  5831,  5496,  2010,  2567,  1010,  3183,  2002,\n",
      "         2170,  1000,  1996,  7409,  1000,  1010,  1997,  9969,  4487, 23809,\n",
      "         3436,  2010,  3350,  1012,   102,  7727,  2000,  2032,  2004,  2069,\n",
      "         1000,  1996,  7409,  1000,  1010,  2572,  3217,  5831,  5496,  2010,\n",
      "         2567,  1997,  9969,  4487, 23809,  3436,  2010,  3350,  1012,   102,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "# def get_features_old(task, df = None):\n",
    "#   if task == 'cola':\n",
    "#     return get_features_cola(df)\n",
    "    \n",
    "def get_features(df):\n",
    "    # Get the lists of sentences and their labels.\n",
    "    if TASK == 'cola':\n",
    "        sentences = df.sentence.values\n",
    "    if TASK == 'MRPC':\n",
    "        sentences = df[['text_a', 'text_b']].values.tolist()\n",
    "    labels = df.label.values.astype(int)\n",
    "\n",
    "    # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    token_type_ids = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in sentences:\n",
    "        # `encode_plus` will:\n",
    "        #   (1) Tokenize the sentence.\n",
    "        #   (2) Prepend the `[CLS]` token to the start.\n",
    "        #   (3) Append the `[SEP]` token to the end.\n",
    "        #   (4) Map tokens to their IDs.\n",
    "        #   (5) Pad or truncate the sentence to `max_length`\n",
    "        #   (6) Create attention masks for [PAD] tokens.\n",
    "        if TASK == 'MRPC':\n",
    "            text_b = sent[1]\n",
    "            sent = sent[0]\n",
    "        else:\n",
    "            text_b = None\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            text = sent,\n",
    "                            text_pair = text_b,\n",
    "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                            max_length = 64,           # Pad & truncate all sentences.\n",
    "                            pad_to_max_length = True,\n",
    "                            return_attention_mask = True,   # Construct attn. masks.\n",
    "                            return_tensors = 'pt', \n",
    "                            truncation = True # Return pytorch tensors.\n",
    "                       )\n",
    "        if TASK == 'MRPC':\n",
    "            token_type_ids.append(encoded_dict['token_type_ids'])\n",
    "\n",
    "        # Add the encoded sentence to the list.    \n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "        # And its attention mask (simply differentiates padding from non-padding).\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "    # Convert the lists into tensors.\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    # Print sentence 0, now as a list of IDs.\n",
    "    print('Original: ', sentences[0])\n",
    "    print('Token IDs:', input_ids[0])\n",
    "    ret = [input_ids, attention_masks, labels]\n",
    "    if TASK == 'MRPC':\n",
    "        token_type_ids = torch.cat(token_type_ids, dim=0)\n",
    "        ret += [token_type_ids]\n",
    "    else:\n",
    "        ret += [None]\n",
    "    return ret\n",
    "  \n",
    "input_ids, attention_masks, labels, token_type_ids = get_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "if token_type_ids is not None:\n",
    "    token_type_ids = [token_type_ids]\n",
    "else:\n",
    "    token_type_ids = []\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels, *token_type_ids)\n",
    "def get_kfold(input_ids, attention_masks, labels, token_type_ids, k=3):\n",
    "  dataset = TensorDataset(input_ids, attention_masks, labels, *token_type_ids)\n",
    "  idx = np.arange(len(input_ids))\n",
    "  np.random.shuffle(idx)\n",
    "\n",
    "  fold_length = len(input_ids)//k\n",
    "  data = []\n",
    "\n",
    "  for i in range(k):\n",
    "    start_idx = i*fold_length\n",
    "    end_idx = (i+1)*fold_length\n",
    "    if i == k-1:\n",
    "      end_idx = len(input_ids)\n",
    "\n",
    "    validation_idx = idx[start_idx: end_idx]\n",
    "    train_idx = np.concatenate((idx[0: start_idx], idx[end_idx: len(input_ids)]))\n",
    "    validation_set = TensorDataset(*dataset[validation_idx])\n",
    "    training_set = TensorDataset(*dataset[train_idx])\n",
    "\n",
    "    data.append((training_set, validation_set))\n",
    "  return data\n",
    "  \n",
    "data = get_kfold(input_ids, attention_masks, labels, token_type_ids, k=3)\n",
    "full_dataset = TensorDataset(input_ids, attention_masks, labels, *token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "batch_size = 32\n",
    "from torch import optim\n",
    "import random\n",
    "import numpy as np\n",
    "import pdb\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "def check_mcc(model, prediction_dataloader):\n",
    "    predictions, true_labels = make_predictions(model, prediction_dataloader)\n",
    "    true_labels = np.concatenate(true_labels)\n",
    "    preds = np.concatenate(predictions)\n",
    "    preds = preds.argmax(1)\n",
    "    return matthews_corrcoef(true_labels, preds)\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "def make_predictions(model, prediction_dataloader):\n",
    "    # Prediction on test set\n",
    "    model.eval()\n",
    "    predictions , true_labels = [], []\n",
    "    for batch in prediction_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, token_type_ids=None, \n",
    "                          attention_mask=b_input_mask)\n",
    "        logits = outputs[0]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        predictions.append(logits)\n",
    "        true_labels.append(label_ids)\n",
    "    model.train()\n",
    "    return predictions, true_labels\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "def train_model(\n",
    "    epochs, train_dataloader, validation_dataloader, \n",
    "    verbose = False, release = False, prediction_dataloader = None,\n",
    "    lr = 2e-5, lrbase = 1e-5, lrclass = 1e-4):\n",
    "    \n",
    "    \n",
    "  model = BertForSequenceClassification.from_pretrained(\n",
    "      \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "      num_labels = 2, \n",
    "      output_attentions = False, # Whether the model returns attentions weights.\n",
    "      output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    "  )\n",
    "  mcc_arr = []\n",
    "  model = model.to(device)\n",
    "  \n",
    "  optimizer = AdamW(model.classifier.parameters(),\n",
    "                    lr = lr, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                    eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                  )\n",
    "#   optimizer = optim.Adam([\n",
    "# #                 {'params': model.bert.parameters(), 'lr': lrbase},\n",
    "#                 {'params': model.classifier.parameters(), 'lr': lrclass}],\n",
    "#                     lr = lr/10, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "#                     eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "#                   )\n",
    "# optim.SGD([\n",
    "#                 {'params': model.base.parameters()},\n",
    "#                 {'params': model.classifier.parameters(), 'lr': 1e-3}\n",
    "#             ], lr=1e-2, momentum=0.9)\n",
    "  total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "#   scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "#                                               num_warmup_steps = 0, # Default value in run_glue.py\n",
    "#                                               num_training_steps = total_steps)\n",
    "    \n",
    "#   initval = [v.cpu().detach().numpy() for v in model.parameters()]\n",
    "  # We'll store a number of quantities such as training and validation loss, \n",
    "  # validation accuracy, and timings.\n",
    "  training_stats = []\n",
    "\n",
    "  total_t0 = time.time()\n",
    "  for epoch_i in range(0, epochs):\n",
    "      if verbose:\n",
    "          print(\"\")\n",
    "          print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "          print('Training...')\n",
    "\n",
    "      t0 = time.time()\n",
    "      total_train_loss = 0\n",
    "      model.train()\n",
    "      for step, batch in enumerate(train_dataloader):\n",
    "          if step % 40 == 0 and not step == 0:\n",
    "              elapsed = format_time(time.time() - t0)\n",
    "              print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(\n",
    "                  step, len(train_dataloader), elapsed))\n",
    "              if release:\n",
    "                mcc = check_mcc(model, prediction_dataloader)\n",
    "                print('mcc: ', mcc)\n",
    "          b_input_ids = batch[0].to(device)\n",
    "          b_input_mask = batch[1].to(device)\n",
    "          b_labels = batch[2].to(device).long()\n",
    "          if len(batch) > 3:\n",
    "            b_token_type_ids = batch[3].to(device)\n",
    "          else:\n",
    "            b_token_type_ids = None\n",
    "          model.zero_grad()\n",
    "          loss, logits = model(b_input_ids,  \n",
    "                               attention_mask=b_input_mask, \n",
    "                               labels=b_labels,\n",
    "                               token_type_ids = b_token_type_ids)\n",
    "          total_train_loss += loss.item()\n",
    "          loss.backward()\n",
    "          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "#           tempval = [v.cpu().detach().numpy() for v in model.parameters()]\n",
    "          optimizer.step()\n",
    "#           scheduler.step()\n",
    "#           newval = [v.cpu().detach().numpy() for v in model.parameters()]\n",
    "      avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "      training_time = format_time(time.time() - t0)\n",
    "\n",
    "      if verbose:\n",
    "          print(\"\")\n",
    "          print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "          print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "\n",
    "          print(\"\")\n",
    "          print(\"Running Validation...\")\n",
    "      if epoch_i == 0:\n",
    "        optimizer = AdamW(model.parameters(),\n",
    "                            lr = lr, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                            eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                          )\n",
    "#         optimizer = optim.Adam([\n",
    "#                         {'params': model.bert.parameters(), 'lr': lrbase},\n",
    "#                         {'params': model.classifier.parameters(), 'lr': lrclass}],\n",
    "#                             lr = lr/10, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "#                             eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "#                           )\n",
    "      t0 = time.time()\n",
    "      if release:\n",
    "        mcc = check_mcc(model, prediction_dataloader)\n",
    "        print('mcc: ', mcc)\n",
    "        mcc_arr.append(mcc)\n",
    "        continue\n",
    "      model.eval()\n",
    "\n",
    "      total_eval_accuracy = 0\n",
    "      total_eval_loss = 0\n",
    "      nb_eval_steps = 0\n",
    "\n",
    "      for batch in validation_dataloader:\n",
    "          b_input_ids = batch[0].to(device)\n",
    "          b_input_mask = batch[1].to(device)\n",
    "          b_labels = batch[2].to(device).long()\n",
    "          if len(batch) > 3:\n",
    "            b_token_type_ids = batch[3].to(device)\n",
    "          else:\n",
    "            b_token_type_ids = None\n",
    "          with torch.no_grad():        \n",
    "              (loss, logits) = model(b_input_ids, \n",
    "                                     token_type_ids=b_token_type_ids, \n",
    "                                     attention_mask=b_input_mask,\n",
    "                                     labels=b_labels)\n",
    "          total_eval_loss += loss.item()\n",
    "          logits = logits.detach().cpu().numpy()\n",
    "          label_ids = b_labels.to('cpu').numpy()\n",
    "          total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "      avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "      print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "      avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "      # Measure how long the validation run took.\n",
    "      validation_time = format_time(time.time() - t0)\n",
    "\n",
    "      print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "      print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "      # Record all statistics from this epoch.\n",
    "      training_stats.append(\n",
    "          {\n",
    "              'epoch': epoch_i + 1,\n",
    "              'Training Loss': avg_train_loss,\n",
    "              'Valid. Loss': avg_val_loss,\n",
    "              'Valid. Accur.': avg_val_accuracy,\n",
    "              'Training Time': training_time,\n",
    "              'Validation Time': validation_time\n",
    "          }\n",
    "      )\n",
    "  if release:\n",
    "    return _, _, mcc_arr, model\n",
    "  print(\"\")\n",
    "  print(\"Training complete!\")\n",
    "\n",
    "  print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
    "  return avg_val_accuracy, avg_val_loss, training_stats, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XGUqOCtgqGhP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# avg_val_accuracies, avg_val_losses = [], []\n",
    "# for train_dataset, val_dataset in data:\n",
    "#   train_dataloader = DataLoader(\n",
    "#               train_dataset,  # The training samples.\n",
    "#               sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "#               batch_size = batch_size # Trains with this batch size.\n",
    "#           )\n",
    "#   validation_dataloader = DataLoader(\n",
    "#               val_dataset, # The validation samples.\n",
    "#               sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "#               batch_size = batch_size # Evaluate with this batch size.\n",
    "#           )\n",
    "\n",
    "\n",
    "#   epochs = 2\n",
    "#   avg_val_accuracy, avg_val_loss, training_stats, model = train_model(\n",
    "#       epochs, train_dataloader, validation_dataloader)\n",
    "#   avg_val_accuracies.append(avg_val_accuracy)\n",
    "#   avg_val_losses.append(avg_val_loss)\n",
    "#   val_loss, val_acc = [sum(arr) / len(arr) for arr in [avg_val_losses, avg_val_accuracies]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "6O_NbXFGMukX",
    "outputId": "6686e966-46a5-4445-f899-d1f4f79a2927"
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Display floats with two decimal places.\n",
    "# pd.set_option('precision', 2)\n",
    "\n",
    "# # Create a DataFrame from our training statistics.\n",
    "# df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# # Use the 'epoch' as the row index.\n",
    "# df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# # A hack to force the column headers to wrap.\n",
    "# #df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# # Display the table.\n",
    "# df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "colab_type": "code",
    "id": "68xreA9JAmG5",
    "outputId": "265c6738-9f28-4817-a350-a63a1ac01934"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Use plot styling from seaborn.\n",
    "# sns.set(style='darkgrid')\n",
    "\n",
    "# # Increase the plot size and font size.\n",
    "# sns.set(font_scale=1.5)\n",
    "# plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# # Plot the learning curve.\n",
    "# plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "# plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# # Label the plot.\n",
    "# plt.title(\"Training & Validation Loss\")\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.legend()\n",
    "# plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "mAN0LZBOOPVh",
    "outputId": "e97be795-f802-4c2e-8f2b-d2ac5cd2eead",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if TASK == 'cola':\n",
    "    df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', \n",
    "                 header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "    sentences = df.sentence.values\n",
    "    labels = df.label.values\n",
    "if TASK == 'MRPC':\n",
    "    sentences = df[['text_a', 'text_b']].values.tolist()\n",
    "    labels = df.label.values.astype(int)\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    if TASK == 'MRPC':\n",
    "        text_b = sent[1]\n",
    "        sent = sent[0]\n",
    "    else:\n",
    "        text_b = None\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text = sent,\n",
    "                        text_pair = text_b,\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 64,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt', \n",
    "                        truncation = True # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "16lctEOyNFik"
   },
   "source": [
    "## 5.2. Evaluate on Test Set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rhR99IISNMg9"
   },
   "source": [
    "\n",
    "With the test set prepared, we can apply our fine-tuned model to generate predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    40  of    182.    Elapsed: 0:00:33.\n",
      "mcc:  0.03993969119737857\n",
      "  Batch    80  of    182.    Elapsed: 0:01:55.\n",
      "mcc:  -0.0008685400478225897\n",
      "  Batch   120  of    182.    Elapsed: 0:03:16.\n",
      "mcc:  0.011194644156224846\n",
      "  Batch   160  of    182.    Elapsed: 0:04:38.\n",
      "mcc:  0.023934584768759443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leedt\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mcc:  0.0\n",
      "  Batch    40  of    182.    Elapsed: 0:00:41.\n",
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:02:10.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:03:39.\n",
      "mcc:  0.0\n",
      "  Batch   160  of    182.    Elapsed: 0:05:08.\n",
      "mcc:  0.0\n",
      "mcc:  0.0\n",
      "  Batch    40  of    182.    Elapsed: 0:00:40.\n",
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:02:12.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:03:06.\n",
      "mcc:  0.0\n",
      "  Batch   160  of    182.    Elapsed: 0:03:31.\n",
      "mcc:  0.0\n",
      "mcc:  0.0\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:00:37.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:01:03.\n",
      "mcc:  0.0\n",
      "  Batch   160  of    182.    Elapsed: 0:01:29.\n",
      "mcc:  0.0\n",
      "mcc:  0.0\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:00:37.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:01:03.\n",
      "mcc:  0.0\n",
      "  Batch   160  of    182.    Elapsed: 0:01:30.\n",
      "mcc:  0.0\n",
      "mcc:  0.0\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:00:37.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:01:04.\n",
      "mcc:  0.0\n",
      "  Batch   160  of    182.    Elapsed: 0:01:30.\n",
      "mcc:  0.0\n",
      "mcc:  0.0\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:01:04.\n",
      "mcc:  0.0\n",
      "  Batch   160  of    182.    Elapsed: 0:01:31.\n",
      "mcc:  0.0\n",
      "mcc:  0.0\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:01:04.\n",
      "mcc:  0.0\n",
      "  Batch   160  of    182.    Elapsed: 0:01:31.\n",
      "mcc:  0.0\n",
      "mcc:  0.0\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:01:04.\n",
      "mcc:  0.0\n",
      "  Batch   160  of    182.    Elapsed: 0:01:31.\n",
      "mcc:  0.0\n",
      "mcc:  0.0\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:01:04.\n",
      "mcc:  0.0\n",
      "  Batch   160  of    182.    Elapsed: 0:01:31.\n",
      "mcc:  0.0\n",
      "mcc:  0.0\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:01:04.\n",
      "mcc:  0.0\n",
      "  Batch   160  of    182.    Elapsed: 0:01:31.\n",
      "mcc:  0.0\n",
      "mcc:  0.0\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:01:04.\n",
      "mcc:  0.0\n",
      "  Batch   160  of    182.    Elapsed: 0:01:31.\n",
      "mcc:  0.0\n",
      "mcc:  0.0\n",
      "      lr                                            mcc_arr\n",
      "0  0.001  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    40  of    182.    Elapsed: 0:00:10.\n",
      "mcc:  -0.0018922332193590198\n",
      "  Batch    80  of    182.    Elapsed: 0:00:36.\n",
      "mcc:  -0.00803553165872111\n",
      "  Batch   120  of    182.    Elapsed: 0:01:03.\n",
      "mcc:  0.014768289370643053\n",
      "  Batch   160  of    182.    Elapsed: 0:01:29.\n",
      "mcc:  0.043696871732587836\n",
      "mcc:  -0.014049114204928588\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leedt\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.0\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.0\n",
      "mcc:  0.0\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.0\n",
      "  Batch   160  of    182.    Elapsed: 0:01:31.\n",
      "mcc:  0.0\n",
      "mcc:  0.0\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.0\n",
      "  Batch   160  of    182.    Elapsed: 0:01:31.\n",
      "mcc:  0.0\n",
      "mcc:  0.0\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.0\n",
      "  Batch   160  of    182.    Elapsed: 0:01:31.\n",
      "mcc:  0.0\n",
      "mcc:  0.0\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.0\n",
      "  Batch   160  of    182.    Elapsed: 0:01:31.\n",
      "mcc:  0.0\n",
      "mcc:  0.0\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.0\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.0\n",
      "mcc:  0.0\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.0\n",
      "  Batch   160  of    182.    Elapsed: 0:01:31.\n",
      "mcc:  0.0\n",
      "mcc:  0.0\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.0\n",
      "  Batch   160  of    182.    Elapsed: 0:01:31.\n",
      "mcc:  0.0\n",
      "mcc:  0.0\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.0\n",
      "  Batch   160  of    182.    Elapsed: 0:01:31.\n",
      "mcc:  0.0\n",
      "mcc:  0.0\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.0\n",
      "  Batch   160  of    182.    Elapsed: 0:01:31.\n",
      "mcc:  0.0\n",
      "mcc:  0.0\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.0\n",
      "  Batch   160  of    182.    Elapsed: 0:01:31.\n",
      "mcc:  0.0\n",
      "mcc:  0.0\n",
      "       lr                                            mcc_arr\n",
      "0  0.0010  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "1  0.0003  [-0.014049114204928588, 0.0, 0.0, 0.0, 0.0, 0....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    40  of    182.    Elapsed: 0:00:10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leedt\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:00:36.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:01:02.\n",
      "mcc:  0.0\n",
      "  Batch   160  of    182.    Elapsed: 0:01:29.\n",
      "mcc:  0.0\n",
      "mcc:  0.0\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.0\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.29431658561844287\n",
      "mcc:  0.0\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.04256627056258761\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.0\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.06688091253827974\n",
      "mcc:  0.023934584768759443\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.07996664213555398\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.07958820679758515\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.12599440314598198\n",
      "mcc:  0.027639661572514115\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.08767694999948683\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.2719241133549627\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.10074455837698007\n",
      "mcc:  0.03910187696682232\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.1527024090497631\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.4846668958551588\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.23480213155051213\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.12804639652696223\n",
      "mcc:  0.06188963035061359\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.04790636553068472\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.06782016042161429\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.20277544848231555\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.3915227373688964\n",
      "mcc:  0.19134983402571426\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.21895200263309897\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.30166569784190744\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.4508367539976906\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.1702958641334236\n",
      "mcc:  0.2096738869257113\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.18990860861236952\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.385463310342515\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.27340194486244945\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.40210562912933057\n",
      "mcc:  0.4118330493468033\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.1694675146764882\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.5166506230519038\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.3851337050221227\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.2952245286163538\n",
      "mcc:  0.21383587141682953\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.3832175807197308\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.4604998635216791\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.43047594195657657\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.5087836565041957\n",
      "mcc:  0.281977404611603\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.33826361302486524\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.35561387942608863\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.3182065078308561\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.5249292217358544\n",
      "mcc:  0.4630281000813379\n",
      "       lr                                            mcc_arr\n",
      "0  0.0010  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "1  0.0003  [-0.014049114204928588, 0.0, 0.0, 0.0, 0.0, 0....\n",
      "2  0.0001  [0.0, 0.0, 0.023934584768759443, 0.02763966157...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    40  of    182.    Elapsed: 0:00:10.\n",
      "mcc:  0.0065779153979125295\n",
      "  Batch    80  of    182.    Elapsed: 0:00:36.\n",
      "mcc:  -0.013038200940868744\n",
      "  Batch   120  of    182.    Elapsed: 0:01:02.\n",
      "mcc:  0.0059432268559915825\n",
      "  Batch   160  of    182.    Elapsed: 0:01:29.\n",
      "mcc:  0.001638439231386689\n",
      "mcc:  -0.003202049338491656\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leedt\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.0\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.1694304930717178\n",
      "mcc:  0.13661911469460392\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.016575698871528398\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.15215500107820965\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.24628331995832906\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.0925799017371132\n",
      "mcc:  0.0919213237708946\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.21075207252499334\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.3395581540276749\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.355042343208434\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.1912423128330618\n",
      "mcc:  0.16245738384504602\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.1321463593481665\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.34225295886105517\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.5490646871000713\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.2238676713241704\n",
      "mcc:  0.1533529407997797\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.33758755789361417\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.2949677578340435\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.21334731291828798\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.642913922980069\n",
      "mcc:  0.3174794884877414\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.46779861736961675\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.3724228058598839\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.5018840809223958\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.5070231759967168\n",
      "mcc:  0.5170818960825005\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.34631030416543224\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.5831874462670753\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.5104031205698893\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.4326084955287106\n",
      "mcc:  0.3988050604939871\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.4371629105198175\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.5632719022766237\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.5508117934988648\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.40476520104159525\n",
      "mcc:  0.3731496401868195\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.3359829847638861\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.2639333343440164\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.4532866258607285\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.5148427746455593\n",
      "mcc:  0.18937163126074982\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.38865439487155684\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.3793735845701082\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.3090344437270349\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.3964335403901154\n",
      "mcc:  0.41290860989780404\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.4075601604252604\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.27320429783231237\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.25541165902232826\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.47723396154746284\n",
      "mcc:  0.3072585551911453\n",
      "        lr                                            mcc_arr\n",
      "0  0.00100  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "1  0.00030  [-0.014049114204928588, 0.0, 0.0, 0.0, 0.0, 0....\n",
      "2  0.00010  [0.0, 0.0, 0.023934584768759443, 0.02763966157...\n",
      "3  0.00003  [-0.003202049338491656, 0.13661911469460392, 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    40  of    182.    Elapsed: 0:00:10.\n",
      "mcc:  0.0024249758082518073\n",
      "  Batch    80  of    182.    Elapsed: 0:00:36.\n",
      "mcc:  -0.0023227037372052796\n",
      "  Batch   120  of    182.    Elapsed: 0:01:02.\n",
      "mcc:  0.008348247103938803\n",
      "  Batch   160  of    182.    Elapsed: 0:01:28.\n",
      "mcc:  0.006256004494874314\n",
      "mcc:  0.00597381044364881\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.010404466372670675\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.008482352436471892\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  -0.003202049338491656\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leedt\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mcc:  0.0\n",
      "mcc:  0.0\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.0\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.0\n",
      "mcc:  0.0\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.0\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.0\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.013816256229801286\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.0\n",
      "mcc:  0.0\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.013816256229801286\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.03271034483714239\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  -0.006433859291514733\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.01668562540732215\n",
      "mcc:  0.0073773929629406395\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.0009456270279599596\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.0239350752119606\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.02049705509309067\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.0073773929629406395\n",
      "mcc:  0.02049705509309067\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.01668562540732215\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.02049705509309067\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.014488605405998828\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.01668562540732215\n",
      "mcc:  0.008750362738622355\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.023117729584548687\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.023117729584548687\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.014488605405998828\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.026629462780229058\n",
      "mcc:  0.03768251729994786\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.03768251729994786\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.01668562540732215\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.012378084407967688\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.053688912035371544\n",
      "mcc:  0.04628957114645965\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.053688912035371544\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.042171938310534764\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.03271034483714239\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.04990632405075438\n",
      "mcc:  0.04422123735534245\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.05539970341392446\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.06026551413787354\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.05192743358037594\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.06479357164266812\n",
      "mcc:  0.08005146936256831\n",
      "  Batch    40  of    182.    Elapsed: 0:00:11.\n",
      "mcc:  0.05868469996045077\n",
      "  Batch    80  of    182.    Elapsed: 0:00:38.\n",
      "mcc:  0.0726040886204337\n",
      "  Batch   120  of    182.    Elapsed: 0:01:05.\n",
      "mcc:  0.06479357164266812\n",
      "  Batch   160  of    182.    Elapsed: 0:01:32.\n",
      "mcc:  0.06395467649951661\n",
      "mcc:  0.05192743358037594\n",
      "        lr                                            mcc_arr\n",
      "0  0.00100  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "1  0.00030  [-0.014049114204928588, 0.0, 0.0, 0.0, 0.0, 0....\n",
      "2  0.00010  [0.0, 0.0, 0.023934584768759443, 0.02763966157...\n",
      "3  0.00003  [-0.003202049338491656, 0.13661911469460392, 0...\n",
      "4  0.00001  [0.00597381044364881, 0.0, 0.0, 0.0, 0.0073773...\n"
     ]
    }
   ],
   "source": [
    "dfhyper = pd.DataFrame()\n",
    "epochs = 12\n",
    "mccs = []\n",
    "full_dataloader = DataLoader(\n",
    "    full_dataset,  # The training samples.\n",
    "    sampler = RandomSampler(full_dataset), # Select batches randomly\n",
    "    batch_size = batch_size # Trains with this batch size.\n",
    "    )\n",
    "if TASK == 'cola':\n",
    "    lrs = [4e-5, 2e-5, 1e-5]\n",
    "if TASK == 'MRPC':\n",
    "    lrs = [1e-3, 3e-4, 1e-4, 3e-5, 1e-5]\n",
    "\n",
    "for lr in lrs:\n",
    "    _, _, mcc_arr, model = train_model(\n",
    "      epochs, full_dataloader, None, release = True, lr=lr,\n",
    "      prediction_dataloader = prediction_dataloader)\n",
    "    del model\n",
    "    dfhyper = dfhyper.append({'lr':lr, 'mcc_arr':mcc_arr}, ignore_index=True)\n",
    "    mccs.append(mcc_arr)\n",
    "    print(dfhyper)\n",
    "# for lrbase in [3e-4, 1e-4, 3e-5, 1e-5][::-1]:\n",
    "#     for lrclass in [3e-4, 1e-4, 3e-5, 1e-5]:\n",
    "#         epochs = 6\n",
    "#         _, _, mcc_arr, model = train_model(\n",
    "#           epochs, full_dataloader, None, release = True, lrclass=lrclass, lrbase=lrbase,\n",
    "#           prediction_dataloader = prediction_dataloader)\n",
    "#         del model\n",
    "#         dfhyper.append({'lrbase':lrbase, 'lrclass':lrclass, 'mcc_arr':mcc_arr}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.001, [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
      "(0.0003, [-0.014049114204928588, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
      "(0.0001, [0.0, 0.0, 0.023934584768759443, 0.027639661572514115, 0.03910187696682232, 0.06188963035061359, 0.19134983402571426, 0.2096738869257113, 0.4118330493468033, 0.21383587141682953, 0.281977404611603, 0.4630281000813379])\n",
      "(3e-05, [-0.003202049338491656, 0.13661911469460392, 0.0919213237708946, 0.16245738384504602, 0.1533529407997797, 0.3174794884877414, 0.5170818960825005, 0.3988050604939871, 0.3731496401868195, 0.18937163126074982, 0.41290860989780404, 0.3072585551911453])\n",
      "(1e-05, [0.00597381044364881, 0.0, 0.0, 0.0, 0.0073773929629406395, 0.02049705509309067, 0.008750362738622355, 0.03768251729994786, 0.04628957114645965, 0.04422123735534245, 0.08005146936256831, 0.05192743358037594])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(f) for f in zip(dfhyper['lr'],dfhyper['mcc_arr'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sdfsdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-fa65e4c5ad0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msdfsdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sdfsdf' is not defined"
     ]
    }
   ],
   "source": [
    "sdfsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_dataloader = DataLoader(\n",
    "#           full_dataset,  # The training samples.\n",
    "#           sampler = RandomSampler(full_dataset), # Select batches randomly\n",
    "#           batch_size = batch_size # Trains with this batch size.\n",
    "#       )\n",
    "\n",
    "# epochs = 6\n",
    "# _, _, mcc_arr, model = train_model(\n",
    "#   epochs, full_dataloader, None, release = True, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "6ulTWaOr8QNY",
    "outputId": "a5517081-2e05-4244-c8df-77a9558ff75a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "\n",
    "output_dir = './model_save/'\n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# They can then be reloaded using `from_pretrained()`\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# Good practice: save your training arguments together with the trained model\n",
    "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z-tjHkR7lc1I"
   },
   "source": [
    "Let's check out the file sizes, out of curiosity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "mqMzI3VTCZo5",
    "outputId": "6df0b283-6458-4d95-8455-2e7537193d1b"
   },
   "outputs": [],
   "source": [
    "!ls -l --block-size=K ./model_save/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fr_bt2rFlgDn"
   },
   "source": [
    "The largest file is the model weights, at around 418 megabytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-WUFUIQ8Cu8D",
    "outputId": "70780762-7790-474f-e5c2-304a066945ae"
   },
   "outputs": [],
   "source": [
    "!ls -l --block-size=M ./model_save/pytorch_model.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dzGKvOFAll_e"
   },
   "source": [
    "To save your model across Colab Notebook sessions, download it to your local machine, or ideally copy it to your Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Trr-A-POC18_"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive to this Notebook instance.\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NxlZsafTC-V5"
   },
   "outputs": [],
   "source": [
    "# Copy the model files to a directory in your Google Drive.\n",
    "!cp -r ./model_save/ \"./drive/Shared drives/ChrisMcCormick.AI/Blog Posts/BERT Fine-Tuning/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W0vstijw85SZ"
   },
   "source": [
    "The following functions will load the model back from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nskPzUM084zL"
   },
   "outputs": [],
   "source": [
    "# Load a trained model and vocabulary that you have fine-tuned\n",
    "model = model_class.from_pretrained(output_dir)\n",
    "tokenizer = tokenizer_class.from_pretrained(output_dir)\n",
    "\n",
    "# Copy the model to the GPU.\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QxSMw0FrptiL"
   },
   "outputs": [],
   "source": [
    "# This code is taken from:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L102\n",
    "\n",
    "# Don't apply weight decay to any parameters whose names include these tokens.\n",
    "# (Here, the BERT doesn't have `gamma` or `beta` parameters, only `bias` terms)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "\n",
    "# Separate the `weight` parameters from the `bias` parameters. \n",
    "# - For the `weight` parameters, this specifies a 'weight_decay_rate' of 0.01. \n",
    "# - For the `bias` parameters, the 'weight_decay_rate' is 0.0. \n",
    "optimizer_grouped_parameters = [\n",
    "    # Filter for all parameters which *don't* include 'bias', 'gamma', 'beta'.\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.1},\n",
    "    \n",
    "    # Filter for parameters which *do* include those.\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "# Note - `optimizer_grouped_parameters` only includes the parameter values, not \n",
    "# the names."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT Fine-Tuning Sentence Classification v3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
